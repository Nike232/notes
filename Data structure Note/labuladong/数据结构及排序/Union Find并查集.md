并查集算法是用来解决图中的连通问题，可以在O(1)的时间复杂度内判断两个节点是否连通，以及可以查询当前的连通分量的数量

```java
class UF {
    // 初始化并查集，包含 n 个节点，时间复杂度 O(n)
    public UF(int n);

    // 连接节点 p 和节点 q，时间复杂度 O(1)
    public void union(int p, int q);

    // 查询节点 p 和节点 q 是否连通（是否在同一个连通分量内），时间复杂度 O(1)
    public boolean connected(int p, int q);

    // 查询当前的连通分量数量，时间复杂度 O(1)
    public int count();
}
```
这里讲的连通是指两个节点之间是否有路径可以到达，而不一定非得是直接相连，这也是并查集算法的优秀之处，如果是直接在邻接表或者领接矩阵上操作，则难以做到O(1)的时间复杂度。并查集之所以能做到，是因为运用了连通的性质,若p与q连通，q与r连通，那么p与r也是联通的。

### 并查集的核心原理
并查集的本质还是树结构的延伸

你想想，对于一棵树，其中的所有节点，是不是都只有同一个根节点？

**如果我们想办法把同一个连通分量的节点都放到同一棵树中，把这棵树的根节点作为这个连通分量的代表，那么我们就可以高效实现上面的操作了**。

并查集底层其实是一片森林（若干棵多叉树），每棵树代表一个连通分量：

- `connected(p, q)`：只需要判断 `p` 和 `q` 所在的多叉树的根节点，若相同，则 `p` 和 `q` 在同一棵树中，即连通，否则不连通。
- `count()`：只需要统计一下总共有多少棵树，即可得到连通分量的数量。
- `union(p, q)`：只需要将 `p` 节点所在的这棵树的根节点，接入到 `q` 节点所在的这棵树的根节点下面，即可完成连接操作。注意这里并不是 `p, q` 两个节点的合并，而是两棵树根节点的合并。因为 `p, q` 一旦连通，那么他们所属的连通分量就合并成了同一个更大的连通分量。

综上，并查集中每个节点其实不在乎自己的子节点是谁，只在乎自己的根节点是谁，所以一个并查集节点类似于下面这样：
```java
class UFNode {
    // 节点 id 编号
    int id;

    // 指向父节点的指针
    // 根节点的 parent 指针为空
    UFNode parent;
}
```
因为不在于子节点是谁，只在于根节点，所以我们的节点设置为id以及他的父节点，那么对于每一个节点我们可以做一个find()函数来找到他的根节点，基于能找到根节点，其他几个算法就很轻松实现了。
```java
// 连接节点 p 和节点 q
void union(UFNode p, UFNode q) {
    // 找到节点 p 和节点 q 的根节点
    // 将 p 所在的整棵树接到 q 所在的整棵树下面
    find(p).parent = find(q);
}

// 查询节点 p 和节点 q 是否连通（是否在同一个连通分量内）
boolean connected(UFNode p, UFNode q) {
    return find(p).id == find(q).id;
}

// 查询节点 node 的根节点，时间复杂度取决于树的高度
UFNode find(UFNode node) {
    while (node.parent != null) {
        node = node.parent;
    }
    return node;
}
```
因为这几个方法都要依赖于find方法，而find方法的时间复杂度取决于树的高度。

**所以并查集算法的最终目标，就是要尽可能地降低树的高度，使得树的高度保持常数，这样上面几个方法的时间复杂度就为O(1)了**

未经优化的并查集算法，最坏的情况就是树退化成链表，这样时间复杂度退化成O(n)

这里只是大概解释，深入请详见图中的Union Find 并查集算法